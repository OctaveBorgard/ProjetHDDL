# -*- coding: utf-8 -*-
"""Untitled0.ipynb

Automatically generated by Colab.

Original file is located at
    https://colab.research.google.com/drive/1mdN1jr3MKN0-8_9MqJ44B1iNJFwInPXx

# 1 La théorique

#2a Mise en place : imports, device, dataset
"""

import torch
import torch.nn as nn
import torch.optim as optim
from torch.utils.data import DataLoader
from torchvision import datasets, transforms
import matplotlib.pyplot as plt

device = torch.device("cuda" if torch.cuda.is_available() else "cpu")
print("Device :", device)

# Transformations : on convertit juste l'image en tenseur, valeurs dans [0,1]
transform = transforms.ToTensor()

# Chargement du dataset
train_dataset = datasets.FashionMNIST(
    root="./data",
    train=True,
    download=True,
    transform=transform
)

test_dataset = datasets.FashionMNIST(
    root="./data",
    train=False,
    download=True,
    transform=transform
)

# Hyperparamètre : taille de batch
batch_size = 128

train_loader = DataLoader(train_dataset, batch_size=batch_size, shuffle=True)
test_loader  = DataLoader(test_dataset, batch_size=batch_size, shuffle=False)

"""# 2b Architecture du CVAE (Encoder, Decoder, CVAE), Loss"""

def to_one_hot(labels, num_classes=10, device=device):
    """
    labels: tensor (batch,)
    return: tensor (batch, num_classes)
    """
    return torch.nn.functional.one_hot(labels, num_classes=num_classes).float().to(device)

class Encoder(nn.Module):
    def __init__(self, input_dim=784, label_dim=10, hidden_dim=400, latent_dim=20):
        super().__init__()
        self.fc1 = nn.Linear(input_dim + label_dim, hidden_dim)
        self.fc_mu = nn.Linear(hidden_dim, latent_dim)
        self.fc_logvar = nn.Linear(hidden_dim, latent_dim)
        self.relu = nn.ReLU()

    def forward(self, x, y_onehot):
        # x: (batch, 1, 28, 28)
        x = x.view(x.size(0), -1)                    # (batch, 784)
        h = torch.cat([x, y_onehot], dim=1)          # (batch, 784+10)
        h = self.relu(self.fc1(h))
        mu = self.fc_mu(h)
        logvar = self.fc_logvar(h)
        return mu, logvar


class Decoder(nn.Module):
    def __init__(self, label_dim=10, hidden_dim=400, latent_dim=20, output_dim=784):
        super().__init__()
        self.fc1 = nn.Linear(latent_dim + label_dim, hidden_dim)
        self.fc2 = nn.Linear(hidden_dim, output_dim)
        self.relu = nn.ReLU()
        self.sigmoid = nn.Sigmoid()

    def forward(self, z, y_onehot):
        h = torch.cat([z, y_onehot], dim=1)          # (batch, latent+10)
        h = self.relu(self.fc1(h))
        x_hat = self.sigmoid(self.fc2(h))            # (batch, 784), giá trị [0,1]
        return x_hat


class CVAE(nn.Module):
    def __init__(self, input_dim=784, label_dim=10, hidden_dim=400, latent_dim=20):
        super().__init__()
        self.encoder = Encoder(input_dim, label_dim, hidden_dim, latent_dim)
        self.decoder = Decoder(label_dim, hidden_dim, latent_dim, input_dim)

    def reparameterize(self, mu, logvar):
        std = torch.exp(0.5 * logvar)
        eps = torch.randn_like(std)
        return mu + eps * std

    def forward(self, x, y_onehot):
        mu, logvar = self.encoder(x, y_onehot)
        z = self.reparameterize(mu, logvar)
        x_hat = self.decoder(z, y_onehot)
        return x_hat, mu, logvar

def cvae_loss(x, x_hat, mu, logvar):
    # Đưa x về dạng (batch, 784)
    x = x.view(x.size(0), -1)

    # Reconstruction loss: Binary Cross Entropy (tính trên từng pixel)
    recon_loss = nn.functional.binary_cross_entropy(
        x_hat, x, reduction="sum"
    )

    # KL divergence giữa q(z|x,y) và N(0,I)
    kl = -0.5 * torch.sum(1 + logvar - mu.pow(2) - logvar.exp())

    loss = recon_loss + kl
    return loss, recon_loss, kl

"""#2c model + optimizer+ train"""

latent_dim = 20

model = CVAE(latent_dim=latent_dim).to(device)
optimizer = optim.Adam(model.parameters(), lr=1e-3)

num_epochs = 5

history_total = []
history_recon = []
history_kl = []

for epoch in range(1, num_epochs + 1):
    model.train()
    total_loss = 0.0
    total_recon = 0.0
    total_kl = 0.0

    for x, labels in train_loader:
        x = x.to(device)
        y_onehot = to_one_hot(labels)         # (batch, 10)


        x_hat, mu, logvar = model(x, y_onehot)


        loss, recon_loss, kl = cvae_loss(x, x_hat, mu, logvar)


        optimizer.zero_grad()
        loss.backward()
        optimizer.step()


        total_loss += loss.item()
        total_recon += recon_loss.item()
        total_kl += kl.item()

    history_total.append(total_loss)
    history_recon.append(total_recon)
    history_kl.append(total_kl)

    print(f"Epoch {epoch}/{num_epochs} | "
          f"Loss: {total_loss:.2f} | Recon: {total_recon:.2f} | KL: {total_kl:.2f}")

plt.figure()
plt.plot(history_total, label="Total loss")
plt.plot(history_recon, label="Reconstruction loss")
plt.plot(history_kl, label="KL divergence")
plt.xlabel("Epoch")
plt.ylabel("Loss ")
plt.legend()
plt.show()

"""# 3c Generate 5 samples per class"""

import matplotlib.pyplot as plt
import torch

model.eval()   # switch model to inference mode
num_samples = 5
latent_dim = 20  # must match the latent_dim used during training

# Optional: class names for display
class_names = [
    "T-shirt/top", "Trouser", "Pullover", "Dress", "Coat",
    "Sandal", "Shirt", "Sneaker", "Bag", "Ankle boot"
]

with torch.no_grad():
    for cls in range(10):   # 10 Fashion-MNIST classes

        # Create a one-hot vector for the desired class
        y = torch.zeros(num_samples, 10)
        y[:, cls] = 1
        y = y.to(device)

        # Sample z from the Gaussian prior N(0, I)
        z = torch.randn(num_samples, latent_dim).to(device)

        # Generate images using the decoder
        samples = model.decoder(z, y)   # output shape: (5, 784)
        samples = samples.view(num_samples, 28, 28).cpu()

        # Display the 5 generated images
        fig, axes = plt.subplots(1, num_samples, figsize=(num_samples * 2, 2))
        fig.suptitle(f"Class {cls}: {class_names[cls]}")

        for i in range(num_samples):
            axes[i].imshow(samples[i], cmap="gray")
            axes[i].axis("off")

        plt.show()

